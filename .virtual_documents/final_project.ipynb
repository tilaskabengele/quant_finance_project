





import yfinance as yf
import pandas as pd
import numpy as np
from hmmlearn.hmm import GaussianHMM
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load and preprocess sector data
def load_sector_data(tickers, start_date, end_date):
    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']
    returns = data.pct_change().dropna()
    return data, returns

# Define parameters
sector_tickers = ['XLU', 'XLK', 'XLY', 'XLE', 'XLF']
start_date = "2007-01-01"
end_date = "2024-03-31"
split_date = "2019-09-01"

# Load data
sector_data, sector_returns = load_sector_data(sector_tickers, start_date, end_date)

# Calculate aggregate daily returns and volatility
full_data = sector_returns.mean(axis=1).to_frame(name='Daily_Return')
full_data['Volatility'] = sector_returns.std(axis=1)

# Split into training and test sets
train_data = full_data.loc[:split_date].copy()
test_data = full_data.loc[split_date:].copy()






# Train and validate HMM
def train_hmm(data, n_states=3):
    features = data[['Daily_Return', 'Volatility']].values
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    hmm_model = GaussianHMM(n_components=n_states, covariance_type="full", n_iter=1000, random_state=42)
    hmm_model.fit(features_scaled)
    return hmm_model, scaler

def validate_hmm(hmm_model, data, scaler):
    features = data[['Daily_Return', 'Volatility']].values
    features_scaled = scaler.transform(features)
    regimes = hmm_model.predict(features_scaled)
    log_likelihood = hmm_model.score(features_scaled)
    validated_data = data.copy()
    validated_data['Regime'] = regimes
    return validated_data, log_likelihood

# Train the HMM
n_states = 3
hmm_model, scaler = train_hmm(train_data, n_states)
validated_test_data, out_sample_log_likelihood = validate_hmm(hmm_model, test_data, scaler)

# Add regimes to the full dataset
full_data['Regime'] = hmm_model.predict(scaler.transform(full_data[['Daily_Return', 'Volatility']].values))
sector_returns['Regime'] = full_data['Regime']






def calculate_weights(performance):
    performance += abs(performance.min()) + 1e-6
    return performance / performance.sum()

def compute_portfolio_returns(sector_returns, weights_by_regime, tickers):
    portfolio_returns = []
    for date, row in sector_returns.iterrows():
        regime = row['Regime']
        weights = weights_by_regime.loc[regime]
        portfolio_return = sum(weights[ticker] * row[ticker] for ticker in tickers)
        portfolio_returns.append(portfolio_return)
    return portfolio_returns

# Analyze performance and calculate weights
sector_performance_by_regime = sector_returns.groupby('Regime').mean()
weights_by_regime = sector_performance_by_regime.apply(calculate_weights, axis=1)

# Compute portfolio returns
sector_returns['Portfolio_Return'] = compute_portfolio_returns(sector_returns, weights_by_regime, sector_tickers)
sector_returns['Cumulative_Portfolio_Return'] = (1 + sector_returns['Portfolio_Return']).cumprod()
sector_returns['Equal_Weighted_Return'] = sector_returns[sector_tickers].mean(axis=1)
sector_returns['Cumulative_Equal_Weighted_Return'] = (1 + sector_returns['Equal_Weighted_Return']).cumprod()






def compute_sharpe_ratio(returns):
    return returns.mean() / returns.std()

def compute_sortino_ratio(returns):
    downside_risk = returns[returns < 0].std()
    return returns.mean() / downside_risk

def compute_calmar_ratio(returns, max_drawdown):
    return returns.mean() / abs(max_drawdown)

def compute_max_drawdown(cumulative_returns):
    peak = cumulative_returns.expanding(min_periods=1).max()
    drawdown = (cumulative_returns / peak) - 1
    return drawdown.min()

# Evaluate metrics
max_drawdown_regime_based = compute_max_drawdown(sector_returns['Cumulative_Portfolio_Return'])
max_drawdown_equal_weighted = compute_max_drawdown(sector_returns['Cumulative_Equal_Weighted_Return'])

sharpe_regime_based = compute_sharpe_ratio(sector_returns['Portfolio_Return'])
sharpe_equal_weighted = compute_sharpe_ratio(sector_returns['Equal_Weighted_Return'])

sortino_regime_based = compute_sortino_ratio(sector_returns['Portfolio_Return'])
sortino_equal_weighted = compute_sortino_ratio(sector_returns['Equal_Weighted_Return'])

calmar_regime_based = compute_calmar_ratio(sector_returns['Portfolio_Return'], max_drawdown_regime_based)
calmar_equal_weighted = compute_calmar_ratio(sector_returns['Equal_Weighted_Return'], max_drawdown_equal_weighted)

print(f"Sharpe Ratio (Regime-Based): {sharpe_regime_based}")
print(f"Sharpe Ratio (Equal-Weighted): {sharpe_equal_weighted}")
print(f"Sortino Ratio (Regime-Based): {sortino_regime_based}")
print(f"Sortino Ratio (Equal-Weighted): {sortino_equal_weighted}")
print(f"Calmar Ratio (Regime-Based): {calmar_regime_based}")
print(f"Calmar Ratio (Equal-Weighted): {calmar_equal_weighted}")









def plot_cumulative_returns(data, title):
    plt.figure(figsize=(12, 6))
    plt.plot(data['Cumulative_Portfolio_Return'], label='Regime-Based Portfolio Return')
    plt.plot(data['Cumulative_Equal_Weighted_Return'], label='Equal-Weighted Portfolio Return', linestyle='--')
    plt.title(title)
    plt.xlabel("Date")
    plt.ylabel("Cumulative Return")
    plt.legend()
    plt.show()

def plot_regime_distribution(data, title):
    regime_counts = data['Regime'].value_counts()
    regime_counts.plot(kind='bar', figsize=(8, 4), title=title, color='skyblue')
    plt.xlabel("Regime")
    plt.ylabel("Frequency")
    plt.show()

plot_cumulative_returns(sector_returns, "Portfolio Performance: Regime-Based vs Equal-Weighted")
plot_regime_distribution(full_data, "Regime Distribution Over Time")




